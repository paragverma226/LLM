
# ğŸ¯ RAG Chatbot using LangChain + Streamlit

This project is a **Retrieval-Augmented Generation (RAG)** chatbot built with [LangChain](https://www.langchain.com/) and [Streamlit](https://streamlit.io/). It uses semantic search over a corpus of activity suggestions and generates short, personalized responses using a language model.

You can use either **OpenAI GPT models** or local LLMs like **LLaMA2 via Ollama**.

---

## ğŸ§  What is RAG?

RAG stands for **Retrieval-Augmented Generation**. It improves the accuracy of language models by:
1. **Retrieving** the most relevant documents based on a user query
2. **Augmenting** the prompt with those documents
3. **Generating** an answer using a language model (LLM)

---

## ğŸ“¦ Features

âœ… Activity recommendation chatbot  
âœ… Multi-turn memory (remembers previous messages)  
âœ… Vector similarity search using `FAISS`  
âœ… HuggingFace embeddings  
âœ… Modular, production-ready Python structure  
âœ… Optional Ollama (local LLM) support  

---

## ğŸ Prerequisites

- Python 3.8+
- OpenAI API Key (if using GPT models) or Ollama (for local models)

---

## ğŸš€ Getting Started

### 1. Clone the Repo
```bash
git clone https://github.com/your-username/rag-chatbot.git
cd rag-chatbot/rag_app
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the Chatbot
```bash
streamlit run main.py
```

---

## ğŸ” Using a Local Model (Optional)

To use **LLaMA2 locally via Ollama**:

### 1. Install Ollama  
[https://ollama.com/download](https://ollama.com/download)

### 2. Pull the model
```bash
ollama pull llama2
```

### 3. Update `rag_chain.py`:
Replace:
```python
from langchain.llms import OpenAI
llm = OpenAI(temperature=0.5)
```
With:
```python
from langchain_community.llms import Ollama
llm = Ollama(model="llama2")
```

---

## ğŸ“ Project Structure

```
rag_app/
â”œâ”€â”€ main.py                        # Entry point for Streamlit
â”œâ”€â”€ app/chat.py                   # UI logic
â”œâ”€â”€ chains/rag_chain.py           # RAG pipeline logic
â”œâ”€â”€ memory/conversation.py        # Memory for chat history
â”œâ”€â”€ retriever/vector_store.py     # FAISS + embeddings
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ .streamlit/config.toml        # Streamlit config
```

---

## âœ¨ Example Questions

- "I want to relax and enjoy some nature."
- "What can I do with friends and food?"
- "Iâ€™m looking for something exciting outdoors."

---

## ğŸ§  Technologies Used

- LangChain
- Streamlit
- FAISS
- HuggingFace Transformers
- OpenAI API / Ollama
- SentenceTransformers for embeddings

---

## ğŸ“Œ To-Do (Optional Enhancements)

- âœ… Add PDF/CSV/Text file loader
- âœ… Deploy as FastAPI REST API
- âœ… Add chat history persistence
- âœ… Integrate with Pinecone or Qdrant
- âœ… Support images or multi-modal inputs

---

## ğŸ“ƒ License

This project is open-source under the [MIT License](LICENSE).

---

## ğŸ™‹â€â™‚ï¸ Need Help?

Open an issue or contact [parag_verma226@yahoo.com](mailto:parag_verma226@yahoo.com)

Happy building! ğŸš€
